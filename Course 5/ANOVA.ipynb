{
  "metadata": {
    "kernelspec": {
      "name": "xpython",
      "display_name": "Python 3.13 (XPython)",
      "language": "python"
    },
    "language_info": {
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "version": "3.13.1"
    }
  },
  "nbformat_minor": 5,
  "nbformat": 4,
  "cells": [
    {
      "id": "3ba7833b-f263-4b23-bb90-1312ae6ea203",
      "cell_type": "markdown",
      "source": "# One-way and two-way ANOVA",
      "metadata": {}
    },
    {
      "id": "cfbbfcbc-e64b-4b63-b72a-e9cdebd20390",
      "cell_type": "markdown",
      "source": "Throughout the following exercises, you will learn to use Python to run both a one-way and two-way ANOVA test. You'll also learn to run a post hoc test to analyze the results of a one-way ANOVA test. Before starting on this programming exercise, we strongly recommend watching the video lecture and completing the IVQ for the associated topics.\n\nRecall the following definitions:\n\n**One-way ANOVA:** Compares the means of one continuous dependent variable based on three or more groups of one categorical variable.\n**Two-way ANOVA:** Compares the means of one continuous dependent variable based on three or more groups of two categorical variables.\nAll the information you need for solving this assignment is in this notebook, and all the code you will be implementing will take place within this notebook.\n",
      "metadata": {}
    },
    {
      "id": "1e428261-899b-48e5-a7bb-2a5a66fe5f98",
      "cell_type": "code",
      "source": "!mamba install pandas\n!mamba install seaborn",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "mambajs 0.19.13\n\nSpecs: xeus-python, numpy, matplotlib, pillow, ipywidgets>=8.1.6, ipyleaflet, scipy, pandas\nChannels: emscripten-forge, conda-forge\n\nSolving environment...\nSolving took 0.6082000000029802 seconds\nAll requested packages already installed.\nmambajs 0.19.13\n\nSpecs: xeus-python, numpy, matplotlib, pillow, ipywidgets>=8.1.6, ipyleaflet, scipy, pandas, seaborn\nChannels: emscripten-forge, conda-forge\n\nSolving environment...\nSolving took 0.5593999999985099 seconds\n  Name                          Version                       Build                         Channel                       \n────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n\u001b[0;32m+ patsy                         \u001b[0m1.0.2                         py313h1804a44_0               emscripten-forge              \n\u001b[0;32m+ seaborn                       \u001b[0m0.13.2                        hd8ed1ab_3                    conda-forge                   \n\u001b[0;32m+ seaborn-base                  \u001b[0m0.13.2                        pyhd8ed1ab_3                  conda-forge                   \n\u001b[0;32m+ statsmodels                   \u001b[0m0.14.6                        np22py313h3cf259a_1           emscripten-forge              \n"
        }
      ],
      "execution_count": 4
    },
    {
      "id": "c042b2ef-eafd-4ab0-92a8-f201bf1fceac",
      "cell_type": "code",
      "source": "# Import pandas and seaborn packages\nimport pandas as pd\nimport seaborn as sns",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": 5
    },
    {
      "id": "0ada2c32-8f9f-434e-bee0-09f347f3b536",
      "cell_type": "code",
      "source": "# Load in diamonds data set from seaborn package\n#cache=True → save a local copy and reuse it later\n#cache=False → do not save a local copy; always load fresh\n\ndiamonds = sns.load_dataset('diamonds', cache=False)\n\ndiamonds.head()",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "execution_count": 5,
          "output_type": "execute_result",
          "data": {
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>carat</th>\n      <th>cut</th>\n      <th>color</th>\n      <th>clarity</th>\n      <th>depth</th>\n      <th>table</th>\n      <th>price</th>\n      <th>x</th>\n      <th>y</th>\n      <th>z</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.23</td>\n      <td>Ideal</td>\n      <td>E</td>\n      <td>SI2</td>\n      <td>61.5</td>\n      <td>55.0</td>\n      <td>326</td>\n      <td>3.95</td>\n      <td>3.98</td>\n      <td>2.43</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.21</td>\n      <td>Premium</td>\n      <td>E</td>\n      <td>SI1</td>\n      <td>59.8</td>\n      <td>61.0</td>\n      <td>326</td>\n      <td>3.89</td>\n      <td>3.84</td>\n      <td>2.31</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.23</td>\n      <td>Good</td>\n      <td>E</td>\n      <td>VS1</td>\n      <td>56.9</td>\n      <td>65.0</td>\n      <td>327</td>\n      <td>4.05</td>\n      <td>4.07</td>\n      <td>2.31</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.29</td>\n      <td>Premium</td>\n      <td>I</td>\n      <td>VS2</td>\n      <td>62.4</td>\n      <td>58.0</td>\n      <td>334</td>\n      <td>4.20</td>\n      <td>4.23</td>\n      <td>2.63</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.31</td>\n      <td>Good</td>\n      <td>J</td>\n      <td>SI2</td>\n      <td>63.3</td>\n      <td>58.0</td>\n      <td>335</td>\n      <td>4.34</td>\n      <td>4.35</td>\n      <td>2.75</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
            "text/plain": "   carat      cut color clarity  depth  table  price     x     y     z\n0   0.23    Ideal     E     SI2   61.5   55.0    326  3.95  3.98  2.43\n1   0.21  Premium     E     SI1   59.8   61.0    326  3.89  3.84  2.31\n2   0.23     Good     E     VS1   56.9   65.0    327  4.05  4.07  2.31\n3   0.29  Premium     I     VS2   62.4   58.0    334  4.20  4.23  2.63\n4   0.31     Good     J     SI2   63.3   58.0    335  4.34  4.35  2.75"
          },
          "metadata": {}
        }
      ],
      "execution_count": 6
    },
    {
      "id": "1f722c72-7a07-43f2-8204-9b5ce6ef4001",
      "cell_type": "markdown",
      "source": "**Data cleaning I**\nFor this part of the course, our main focus is on one-way and two-way ANOVA. This means that our dataset needs a continuous variable, and up to two categorical variables.",
      "metadata": {}
    },
    {
      "id": "924d442c-89d1-4cfe-9c34-754eaa6a75b9",
      "cell_type": "code",
      "source": "# Check how many diamonds are each color grade\ndiamonds['color'].value_counts()",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "execution_count": 6,
          "output_type": "execute_result",
          "data": {
            "text/plain": "color\nG    11292\nE     9797\nF     9542\nH     8304\nD     6775\nI     5422\nJ     2808\nName: count, dtype: int64"
          },
          "metadata": {}
        }
      ],
      "execution_count": 7
    },
    {
      "id": "f9fe9808-13ed-4b6b-b454-012804163a4b",
      "cell_type": "code",
      "source": "# Subset for colorless diamonds\ncolorless_diamonds = diamonds[diamonds['color'].isin([\"E\",\"F\",\"H\",\"D\",\"I\"])] \n# Select only color and price columns, and reset index\ncolorless_diamonds = colorless_diamonds[['color','price']].reset_index(drop=True)\ncolorless_diamonds.head()",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "execution_count": 7,
          "output_type": "execute_result",
          "data": {
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>color</th>\n      <th>price</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>E</td>\n      <td>326</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>E</td>\n      <td>326</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>E</td>\n      <td>327</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>I</td>\n      <td>334</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>I</td>\n      <td>336</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
            "text/plain": "  color  price\n0     E    326\n1     E    326\n2     E    327\n3     I    334\n4     I    336"
          },
          "metadata": {}
        }
      ],
      "execution_count": 8
    },
    {
      "id": "d8fe3b4e-443c-407c-85d6-adbb8b52ff57",
      "cell_type": "markdown",
      "source": "**Note:** We took a subset of colorless and near colorless diamonds. We excluded G color grade diamonds as there were many more of them, and we excluded J color grade diamonds as there were significantly fewer of them. In a workplace setting, you would typically go through a more thoughtful process of subsetting. The goal of this notebook is focusing on ANOVA, not data cleaning or variable selection.",
      "metadata": {}
    },
    {
      "id": "dac0db18-098f-45e2-99e1-5c6f3408f6e1",
      "cell_type": "code",
      "source": "# Remove dropped categories of diamond color\ncolorless_diamonds.color = colorless_diamonds.color.cat.remove_categories([\"G\",\"J\"])\n\n# Check that the dropped categories have been removed\ncolorless_diamonds[\"color\"].values",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "execution_count": 16,
          "output_type": "execute_result",
          "data": {
            "text/plain": "['E', 'E', 'E', 'I', 'I', ..., 'D', 'D', 'D', 'H', 'D']\nLength: 39840\nCategories (5, str): ['D', 'E', 'F', 'H', 'I']"
          },
          "metadata": {}
        }
      ],
      "execution_count": 17
    },
    {
      "id": "d121fe5e-77b2-4005-9a21-1d3a8f08f1d3",
      "cell_type": "code",
      "source": "# Import math package\nimport math\n\n# Take the logarithm of the price, and insert it as the third column\ncolorless_diamonds.insert(2, 'log_price', [math.log(price) for price in colorless_diamonds['price']])\n",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "b1d7629d-f3dd-4d0d-8a03-976b9a52015e",
      "cell_type": "markdown",
      "source": "Note: The first argument in the insert() function allows you to specify the location of the new column with a column number. But the argument starts counting at 0. So if you put in 0, that is the first column; if you enter 1, that is the second column, and so on. Since we specified 2, the new log_price column will be the third column.\n\nNext, we use the dropna() function to drop the rows with missing values. Setting the inplace argument to True means that we do not have to save the dataframe as a new variable. Then, we'll reset the index using the reset_index() function to reset the index column to account for the rows we just dropped. The inplace argument works the same as it did for the dropna() function, and the drop argument prevents us from creating a new column with the old index numbers preserved.",
      "metadata": {}
    },
    {
      "id": "e78f12c4-6938-4529-bcb0-ea4b2e005868",
      "cell_type": "code",
      "source": "# Drop rows with missing values and reset index\ncolorless_diamonds.dropna().reset_index(drop=True)\n\ncolorless_diamonds.head()",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "execution_count": 18,
          "output_type": "execute_result",
          "data": {
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>color</th>\n      <th>price</th>\n      <th>log_price</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>E</td>\n      <td>326</td>\n      <td>5.786897</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>E</td>\n      <td>326</td>\n      <td>5.786897</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>E</td>\n      <td>327</td>\n      <td>5.789960</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>I</td>\n      <td>334</td>\n      <td>5.811141</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>I</td>\n      <td>336</td>\n      <td>5.817111</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
            "text/plain": "  color  price  log_price\n0     E    326   5.786897\n1     E    326   5.786897\n2     E    327   5.789960\n3     I    334   5.811141\n4     I    336   5.817111"
          },
          "metadata": {}
        }
      ],
      "execution_count": 19
    },
    {
      "id": "b65419d5-ee27-4eec-af6e-cb004feb76ae",
      "cell_type": "markdown",
      "source": "# One-way ANOVA",
      "metadata": {}
    },
    {
      "id": "cc4b4f18-6ab6-4133-bcb0-d5b918713f9c",
      "cell_type": "markdown",
      "source": "Recall that one-way ANOVA helps us better understand the relationship between a categorical variable and a continuous variable. We'll do some basic exploratory data analysis by creating a boxplot using the boxplot() function from the seaborn package.\n\nBased on the plot, we can observe that there is a lot of overlap in the distribution of log_price for each color of diamond. But we can't tell yet if they are statistically significantly different.",
      "metadata": {}
    },
    {
      "id": "d1f8cd80-f615-43b7-b284-2639b4602556",
      "cell_type": "code",
      "source": "sns.boxplot(x ='color' , y = 'log_price', data =colorless_diamonds)",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "execution_count": 19,
          "output_type": "execute_result",
          "data": {
            "text/plain": "<Axes: xlabel='color', ylabel='log_price'>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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",
            "text/plain": "<Figure size 640x480 with 1 Axes>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 20
    },
    {
      "id": "c16b2d8e-70d3-40c2-91c9-aaad6a25bf90",
      "cell_type": "markdown",
      "source": "In order to run ANOVA, we need to create a regression model. To do this, we'll import the statsmodels.api package and the ols() function. Next, we'll create a simple linear regression model where the X variable is color, which we will code as categorical using C(). Then, we'll fit the model to the data, and generate model summary statistics.",
      "metadata": {}
    },
    {
      "id": "ac2c0c98-d6b2-4604-81ed-0a5e40f74048",
      "cell_type": "code",
      "source": "# Import statsmodels and ols function\nimport statsmodels.api as sm\nfrom statsmodels.formula.api import ols",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": 21
    },
    {
      "id": "ae8ae8c4-75df-4e7a-b99a-75576e890527",
      "cell_type": "code",
      "source": "# Construct simple linear regression model, and fit the model\nols_formula = 'log_price ~ C(color)'\nOLS = ols(formula = ols_formula, data = colorless_diamonds)\nmodel = OLS.fit()",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": 22
    },
    {
      "id": "52613cca-af9c-44a6-a08c-d268bb3f7129",
      "cell_type": "code",
      "source": "# Get summary statistics\nmodel.summary()",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "execution_count": 22,
          "output_type": "execute_result",
          "data": {
            "text/html": "<table class=\"simpletable\">\n<caption>OLS Regression Results</caption>\n<tr>\n  <th>Dep. Variable:</th>        <td>log_price</td>    <th>  R-squared:         </th> <td>   0.026</td> \n</tr>\n<tr>\n  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.026</td> \n</tr>\n<tr>\n  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   265.0</td> \n</tr>\n<tr>\n  <th>Date:</th>             <td>Thu, 12 Feb 2026</td> <th>  Prob (F-statistic):</th> <td>3.61e-225</td>\n</tr>\n<tr>\n  <th>Time:</th>                 <td>19:51:00</td>     <th>  Log-Likelihood:    </th> <td> -56182.</td> \n</tr>\n<tr>\n  <th>No. Observations:</th>      <td> 39840</td>      <th>  AIC:               </th> <td>1.124e+05</td>\n</tr>\n<tr>\n  <th>Df Residuals:</th>          <td> 39835</td>      <th>  BIC:               </th> <td>1.124e+05</td>\n</tr>\n<tr>\n  <th>Df Model:</th>              <td>     4</td>      <th>                     </th>     <td> </td>    \n</tr>\n<tr>\n  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n</tr>\n</table>\n<table class=\"simpletable\">\n<tr>\n        <td></td>           <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n</tr>\n<tr>\n  <th>Intercept</th>     <td>    7.6169</td> <td>    0.012</td> <td>  632.421</td> <td> 0.000</td> <td>    7.593</td> <td>    7.641</td>\n</tr>\n<tr>\n  <th>C(color)[T.E]</th> <td>   -0.0375</td> <td>    0.016</td> <td>   -2.394</td> <td> 0.017</td> <td>   -0.068</td> <td>   -0.007</td>\n</tr>\n<tr>\n  <th>C(color)[T.F]</th> <td>    0.1455</td> <td>    0.016</td> <td>    9.240</td> <td> 0.000</td> <td>    0.115</td> <td>    0.176</td>\n</tr>\n<tr>\n  <th>C(color)[T.H]</th> <td>    0.3015</td> <td>    0.016</td> <td>   18.579</td> <td> 0.000</td> <td>    0.270</td> <td>    0.333</td>\n</tr>\n<tr>\n  <th>C(color)[T.I]</th> <td>    0.4061</td> <td>    0.018</td> <td>   22.479</td> <td> 0.000</td> <td>    0.371</td> <td>    0.441</td>\n</tr>\n</table>\n<table class=\"simpletable\">\n<tr>\n  <th>Omnibus:</th>       <td>7112.992</td> <th>  Durbin-Watson:     </th> <td>   0.065</td>\n</tr>\n<tr>\n  <th>Prob(Omnibus):</th>  <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>1542.881</td>\n</tr>\n<tr>\n  <th>Skew:</th>           <td> 0.079</td>  <th>  Prob(JB):          </th> <td>    0.00</td>\n</tr>\n<tr>\n  <th>Kurtosis:</th>       <td> 2.049</td>  <th>  Cond. No.          </th> <td>    6.32</td>\n</tr>\n</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.",
            "text/latex": "\\begin{center}\n\\begin{tabular}{lclc}\n\\toprule\n\\textbf{Dep. Variable:}    &    log\\_price    & \\textbf{  R-squared:         } &     0.026   \\\\\n\\textbf{Model:}            &       OLS        & \\textbf{  Adj. R-squared:    } &     0.026   \\\\\n\\textbf{Method:}           &  Least Squares   & \\textbf{  F-statistic:       } &     265.0   \\\\\n\\textbf{Date:}             & Thu, 12 Feb 2026 & \\textbf{  Prob (F-statistic):} & 3.61e-225   \\\\\n\\textbf{Time:}             &     19:51:00     & \\textbf{  Log-Likelihood:    } &   -56182.   \\\\\n\\textbf{No. Observations:} &       39840      & \\textbf{  AIC:               } & 1.124e+05   \\\\\n\\textbf{Df Residuals:}     &       39835      & \\textbf{  BIC:               } & 1.124e+05   \\\\\n\\textbf{Df Model:}         &           4      & \\textbf{                     } &             \\\\\n\\textbf{Covariance Type:}  &    nonrobust     & \\textbf{                     } &             \\\\\n\\bottomrule\n\\end{tabular}\n\\begin{tabular}{lcccccc}\n                       & \\textbf{coef} & \\textbf{std err} & \\textbf{t} & \\textbf{P$> |$t$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n\\midrule\n\\textbf{Intercept}     &       7.6169  &        0.012     &   632.421  &         0.000        &        7.593    &        7.641     \\\\\n\\textbf{C(color)[T.E]} &      -0.0375  &        0.016     &    -2.394  &         0.017        &       -0.068    &       -0.007     \\\\\n\\textbf{C(color)[T.F]} &       0.1455  &        0.016     &     9.240  &         0.000        &        0.115    &        0.176     \\\\\n\\textbf{C(color)[T.H]} &       0.3015  &        0.016     &    18.579  &         0.000        &        0.270    &        0.333     \\\\\n\\textbf{C(color)[T.I]} &       0.4061  &        0.018     &    22.479  &         0.000        &        0.371    &        0.441     \\\\\n\\bottomrule\n\\end{tabular}\n\\begin{tabular}{lclc}\n\\textbf{Omnibus:}       & 7112.992 & \\textbf{  Durbin-Watson:     } &    0.065  \\\\\n\\textbf{Prob(Omnibus):} &   0.000  & \\textbf{  Jarque-Bera (JB):  } & 1542.881  \\\\\n\\textbf{Skew:}          &   0.079  & \\textbf{  Prob(JB):          } &     0.00  \\\\\n\\textbf{Kurtosis:}      &   2.049  & \\textbf{  Cond. No.          } &     6.32  \\\\\n\\bottomrule\n\\end{tabular}\n%\\caption{OLS Regression Results}\n\\end{center}\n\nNotes: \\newline\n [1] Standard Errors assume that the covariance matrix of the errors is correctly specified.",
            "text/plain": "<class 'statsmodels.iolib.summary.Summary'>\n\"\"\"\n                            OLS Regression Results                            \n==============================================================================\nDep. Variable:              log_price   R-squared:                       0.026\nModel:                            OLS   Adj. R-squared:                  0.026\nMethod:                 Least Squares   F-statistic:                     265.0\nDate:                Thu, 12 Feb 2026   Prob (F-statistic):          3.61e-225\nTime:                        19:51:00   Log-Likelihood:                -56182.\nNo. Observations:               39840   AIC:                         1.124e+05\nDf Residuals:                   39835   BIC:                         1.124e+05\nDf Model:                           4                                         \nCovariance Type:            nonrobust                                         \n=================================================================================\n                    coef    std err          t      P>|t|      [0.025      0.975]\n---------------------------------------------------------------------------------\nIntercept         7.6169      0.012    632.421      0.000       7.593       7.641\nC(color)[T.E]    -0.0375      0.016     -2.394      0.017      -0.068      -0.007\nC(color)[T.F]     0.1455      0.016      9.240      0.000       0.115       0.176\nC(color)[T.H]     0.3015      0.016     18.579      0.000       0.270       0.333\nC(color)[T.I]     0.4061      0.018     22.479      0.000       0.371       0.441\n==============================================================================\nOmnibus:                     7112.992   Durbin-Watson:                   0.065\nProb(Omnibus):                  0.000   Jarque-Bera (JB):             1542.881\nSkew:                           0.079   Prob(JB):                         0.00\nKurtosis:                       2.049   Cond. No.                         6.32\n==============================================================================\n\nNotes:\n[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n\"\"\""
          },
          "metadata": {}
        }
      ],
      "execution_count": 23
    },
    {
      "id": "667f87c0-7814-44b1-8384-74cbbdb9308e",
      "cell_type": "markdown",
      "source": "Based on the model summary table, the color grades' associated beta coefficients all have a p-value of less than 0.05 (check the P>|t| column). But we can't be sure if there is a significant price difference between the various color grades. This is where one-way ANOVA comes in.\n\nFirst, we have to state our null and alternative hypotheses:\n**Null Hypothesis**\n$H_0$ : $price_D$ = $price_E$ = $price_F$ = $price_H$ = $price_I$\nThere is no difference in the price of diamonds based on color grade.\n**Alternative Hypothesis**\n$H_1$ : Not $price_D$ = $price_E$ = $price_F$ = $price_H$ = $price_I$\nThere is a difference in the price of diamonds based on color grade.",
      "metadata": {}
    },
    {
      "id": "293a45b8-30a2-4024-8150-75195108bcb4",
      "cell_type": "code",
      "source": "# Run one-way ANOVA\nsm.stats.anova_lm(model, type = 1)",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "execution_count": 23,
          "output_type": "execute_result",
          "data": {
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>df</th>\n      <th>sum_sq</th>\n      <th>mean_sq</th>\n      <th>F</th>\n      <th>PR(&gt;F)</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>C(color)</th>\n      <td>4.0</td>\n      <td>1041.690290</td>\n      <td>260.422572</td>\n      <td>264.987395</td>\n      <td>3.609774e-225</td>\n    </tr>\n    <tr>\n      <th>Residual</th>\n      <td>39835.0</td>\n      <td>39148.779822</td>\n      <td>0.982773</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
            "text/plain": "               df        sum_sq     mean_sq           F         PR(>F)\nC(color)      4.0   1041.690290  260.422572  264.987395  3.609774e-225\nResidual  39835.0  39148.779822    0.982773         NaN            NaN"
          },
          "metadata": {}
        }
      ],
      "execution_count": 24
    },
    {
      "id": "6b9b03a6-9682-4f26-863e-c7c54ad7fdf9",
      "cell_type": "code",
      "source": "sm.stats.anova_lm(model, type = 2)",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "execution_count": 24,
          "output_type": "execute_result",
          "data": {
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>df</th>\n      <th>sum_sq</th>\n      <th>mean_sq</th>\n      <th>F</th>\n      <th>PR(&gt;F)</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>C(color)</th>\n      <td>4.0</td>\n      <td>1041.690290</td>\n      <td>260.422572</td>\n      <td>264.987395</td>\n      <td>3.609774e-225</td>\n    </tr>\n    <tr>\n      <th>Residual</th>\n      <td>39835.0</td>\n      <td>39148.779822</td>\n      <td>0.982773</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
            "text/plain": "               df        sum_sq     mean_sq           F         PR(>F)\nC(color)      4.0   1041.690290  260.422572  264.987395  3.609774e-225\nResidual  39835.0  39148.779822    0.982773         NaN            NaN"
          },
          "metadata": {}
        }
      ],
      "execution_count": 25
    },
    {
      "id": "21d51a25-d046-472c-a238-1e8913dd1b6a",
      "cell_type": "code",
      "source": "sm.stats.anova_lm(model, type = 3)",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "execution_count": 25,
          "output_type": "execute_result",
          "data": {
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>df</th>\n      <th>sum_sq</th>\n      <th>mean_sq</th>\n      <th>F</th>\n      <th>PR(&gt;F)</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>C(color)</th>\n      <td>4.0</td>\n      <td>1041.690290</td>\n      <td>260.422572</td>\n      <td>264.987395</td>\n      <td>3.609774e-225</td>\n    </tr>\n    <tr>\n      <th>Residual</th>\n      <td>39835.0</td>\n      <td>39148.779822</td>\n      <td>0.982773</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
            "text/plain": "               df        sum_sq     mean_sq           F         PR(>F)\nC(color)      4.0   1041.690290  260.422572  264.987395  3.609774e-225\nResidual  39835.0  39148.779822    0.982773         NaN            NaN"
          },
          "metadata": {}
        }
      ],
      "execution_count": 26
    },
    {
      "id": "6d1a4483-8ac9-4708-b183-1b72b2001978",
      "cell_type": "markdown",
      "source": "We use the anova_lm() function from the statsmodels.stats package. As noted previously, the function requires a fitted regression model, and for us to specify the type of ANOVA: 1, 2, or 3. You can review the statsmodels documentation to learn more, as well as to this article and this explanation on StackExchange. Since the p-value (column PR(>F)) is very small, we can reject the null hypothesis that the mean of the price is the same for all diamond color grades.\n\n**Technical note:** The type of an ANOVA and the number of ways of an ANOVA are two distinct concepts: \"type\" (typ in statsmodels.stats.anova.anova_lm()) refers to how the sums of squares (these quantities are the building blocks for ANOVA) are calculated, while \"K-way\" means that there are K categorical factors in the analysis.",
      "metadata": {}
    },
    {
      "id": "61b477f6-e02b-4db5-b99a-a1ee1d40afce",
      "cell_type": "markdown",
      "source": "## Data cleaning II",
      "metadata": {}
    },
    {
      "id": "918bd95f-af04-4e71-b62e-037c0034aacd",
      "cell_type": "markdown",
      "source": "In this part of the notebook, we will prepare a second dataset so we can perform a two-way ANOVA, which requires two categorical variables. We will start with the same diamonds dataset from the seaborn package.",
      "metadata": {}
    },
    {
      "id": "5b759bf6-631f-4436-b38b-fba24de07081",
      "cell_type": "code",
      "source": "# Import diamonds data set from seaborn package\ndiamonds = sns.load_dataset('diamonds', cache = False)\ndiamonds.head()",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "execution_count": 26,
          "output_type": "execute_result",
          "data": {
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>carat</th>\n      <th>cut</th>\n      <th>color</th>\n      <th>clarity</th>\n      <th>depth</th>\n      <th>table</th>\n      <th>price</th>\n      <th>x</th>\n      <th>y</th>\n      <th>z</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.23</td>\n      <td>Ideal</td>\n      <td>E</td>\n      <td>SI2</td>\n      <td>61.5</td>\n      <td>55.0</td>\n      <td>326</td>\n      <td>3.95</td>\n      <td>3.98</td>\n      <td>2.43</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.21</td>\n      <td>Premium</td>\n      <td>E</td>\n      <td>SI1</td>\n      <td>59.8</td>\n      <td>61.0</td>\n      <td>326</td>\n      <td>3.89</td>\n      <td>3.84</td>\n      <td>2.31</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.23</td>\n      <td>Good</td>\n      <td>E</td>\n      <td>VS1</td>\n      <td>56.9</td>\n      <td>65.0</td>\n      <td>327</td>\n      <td>4.05</td>\n      <td>4.07</td>\n      <td>2.31</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.29</td>\n      <td>Premium</td>\n      <td>I</td>\n      <td>VS2</td>\n      <td>62.4</td>\n      <td>58.0</td>\n      <td>334</td>\n      <td>4.20</td>\n      <td>4.23</td>\n      <td>2.63</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.31</td>\n      <td>Good</td>\n      <td>J</td>\n      <td>SI2</td>\n      <td>63.3</td>\n      <td>58.0</td>\n      <td>335</td>\n      <td>4.34</td>\n      <td>4.35</td>\n      <td>2.75</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
            "text/plain": "   carat      cut color clarity  depth  table  price     x     y     z\n0   0.23    Ideal     E     SI2   61.5   55.0    326  3.95  3.98  2.43\n1   0.21  Premium     E     SI1   59.8   61.0    326  3.89  3.84  2.31\n2   0.23     Good     E     VS1   56.9   65.0    327  4.05  4.07  2.31\n3   0.29  Premium     I     VS2   62.4   58.0    334  4.20  4.23  2.63\n4   0.31     Good     J     SI2   63.3   58.0    335  4.34  4.35  2.75"
          },
          "metadata": {}
        }
      ],
      "execution_count": 27
    },
    {
      "id": "e64597cd-f041-445e-aff9-ad2f2f204050",
      "cell_type": "markdown",
      "source": "Below, we go through a very similar process as above. We start by selecting the columns of interest: color, cut, and price. Then, we subset only for certain color grades, and remove the dropped colors from the list of categories using the remove_categories() function.\n\nNext, we subset for specific diamond cuts: Ideal, Premium, and Very Good, and remove the dropped cuts from the list of categories.\n\nNext, we remove rows with missing data, and reset the index.\n\nLastly, we add in a column for the logarithm of the price.",
      "metadata": {}
    },
    {
      "id": "0e91103d-e66f-40f1-b2c3-e43926841a79",
      "cell_type": "code",
      "source": "# Subset for color, cut, price columns\ndiamonds2 = diamonds[['color','cut','price']]\n\n# Only include colorless diamonds\ndiamonds2 = diamonds2[diamonds2['color'].isin([\"E\",\"F\",\"H\",\"D\",\"I\"])]\n\n# Drop removed colors, G and J\ndiamonds2.color = diamonds2.color.cat.remove_categories(['G','J'])\n\n# Only include ideal, premium, and very good diamonds\ndiamonds2 = diamonds2[diamonds2['cut'].isin([\"Ideal\",\"Premium\",\"Very Good\"])]\n\n# Drop removed cuts\ndiamonds2.cut = diamonds2.cut.cat.remove_categories([\"Good\",\"Fair\"])\n\n# Drop null and reset index\ndiamonds2 = diamonds2.dropna().reset_index(drop=True)\n\n# Add column for logarithm of price\ndiamonds2.insert(3, 'log_price',[math.log(price) for price in diamonds2['price']])\n\ndiamonds2.head()\n    ",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "execution_count": 40,
          "output_type": "execute_result",
          "data": {
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>color</th>\n      <th>cut</th>\n      <th>price</th>\n      <th>log_price</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>E</td>\n      <td>Ideal</td>\n      <td>326</td>\n      <td>5.786897</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>E</td>\n      <td>Premium</td>\n      <td>326</td>\n      <td>5.786897</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>I</td>\n      <td>Premium</td>\n      <td>334</td>\n      <td>5.811141</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>I</td>\n      <td>Very Good</td>\n      <td>336</td>\n      <td>5.817111</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>H</td>\n      <td>Very Good</td>\n      <td>337</td>\n      <td>5.820083</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
            "text/plain": "  color        cut  price  log_price\n0     E      Ideal    326   5.786897\n1     E    Premium    326   5.786897\n2     I    Premium    334   5.811141\n3     I  Very Good    336   5.817111\n4     H  Very Good    337   5.820083"
          },
          "metadata": {}
        }
      ],
      "execution_count": 41
    },
    {
      "id": "0d2a8979-5a14-41c5-9c9d-36da4dbca0e0",
      "cell_type": "markdown",
      "source": "## Two-Way ANOVA",
      "metadata": {}
    },
    {
      "id": "f30c8e80-2e23-480d-b33a-737844c98619",
      "cell_type": "markdown",
      "source": "we'll create a multiple linear regression model using the ols() function, fit the model to the data, and get the summary statistics.\n\nNote: This regression model includes two categorical X variables: color and cut, and a variable to account for the interaction between color and cut. The interaction is denoted using the : symbol.",
      "metadata": {}
    },
    {
      "id": "2f4c55e5-6c40-4e43-a712-498319b2ff10",
      "cell_type": "code",
      "source": "# Construct a multiple linear regression with an interaction term between color and cut\nmodel2 = ols(formula = \"log_price ~ C(color) + C(cut) + C(color):C(cut)\", \n             data = diamonds2).fit()\n",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": 43
    },
    {
      "id": "2c8d3cdd-c20d-40d4-b3e4-0e4e897709de",
      "cell_type": "code",
      "source": "# Get summary statistics\nmodel2.summary()",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "execution_count": 43,
          "output_type": "execute_result",
          "data": {
            "text/html": "<table class=\"simpletable\">\n<caption>OLS Regression Results</caption>\n<tr>\n  <th>Dep. Variable:</th>        <td>log_price</td>    <th>  R-squared:         </th> <td>   0.046</td> \n</tr>\n<tr>\n  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.045</td> \n</tr>\n<tr>\n  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   119.5</td> \n</tr>\n<tr>\n  <th>Date:</th>             <td>Fri, 13 Feb 2026</td> <th>  Prob (F-statistic):</th>  <td>  0.00</td>  \n</tr>\n<tr>\n  <th>Time:</th>                 <td>09:17:21</td>     <th>  Log-Likelihood:    </th> <td> -49159.</td> \n</tr>\n<tr>\n  <th>No. Observations:</th>      <td> 34935</td>      <th>  AIC:               </th> <td>9.835e+04</td>\n</tr>\n<tr>\n  <th>Df Residuals:</th>          <td> 34920</td>      <th>  BIC:               </th> <td>9.847e+04</td>\n</tr>\n<tr>\n  <th>Df Model:</th>              <td>    14</td>      <th>                     </th>     <td> </td>    \n</tr>\n<tr>\n  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n</tr>\n</table>\n<table class=\"simpletable\">\n<tr>\n                  <td></td>                     <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n</tr>\n<tr>\n  <th>Intercept</th>                         <td>    7.4567</td> <td>    0.019</td> <td>  401.583</td> <td> 0.000</td> <td>    7.420</td> <td>    7.493</td>\n</tr>\n<tr>\n  <th>C(color)[T.E]</th>                     <td>   -0.0056</td> <td>    0.024</td> <td>   -0.231</td> <td> 0.817</td> <td>   -0.053</td> <td>    0.042</td>\n</tr>\n<tr>\n  <th>C(color)[T.F]</th>                     <td>    0.1755</td> <td>    0.024</td> <td>    7.166</td> <td> 0.000</td> <td>    0.128</td> <td>    0.224</td>\n</tr>\n<tr>\n  <th>C(color)[T.H]</th>                     <td>    0.2756</td> <td>    0.026</td> <td>   10.739</td> <td> 0.000</td> <td>    0.225</td> <td>    0.326</td>\n</tr>\n<tr>\n  <th>C(color)[T.I]</th>                     <td>    0.3787</td> <td>    0.028</td> <td>   13.294</td> <td> 0.000</td> <td>    0.323</td> <td>    0.435</td>\n</tr>\n<tr>\n  <th>C(cut)[T.Premium]</th>                 <td>    0.2828</td> <td>    0.031</td> <td>    9.153</td> <td> 0.000</td> <td>    0.222</td> <td>    0.343</td>\n</tr>\n<tr>\n  <th>C(cut)[T.Very Good]</th>               <td>    0.2295</td> <td>    0.031</td> <td>    7.290</td> <td> 0.000</td> <td>    0.168</td> <td>    0.291</td>\n</tr>\n<tr>\n  <th>C(color)[T.E]:C(cut)[T.Premium]</th>   <td>   -0.0322</td> <td>    0.040</td> <td>   -0.800</td> <td> 0.424</td> <td>   -0.111</td> <td>    0.047</td>\n</tr>\n<tr>\n  <th>C(color)[T.F]:C(cut)[T.Premium]</th>   <td>    0.0313</td> <td>    0.040</td> <td>    0.775</td> <td> 0.438</td> <td>   -0.048</td> <td>    0.110</td>\n</tr>\n<tr>\n  <th>C(color)[T.H]:C(cut)[T.Premium]</th>   <td>    0.0947</td> <td>    0.041</td> <td>    2.308</td> <td> 0.021</td> <td>    0.014</td> <td>    0.175</td>\n</tr>\n<tr>\n  <th>C(color)[T.I]:C(cut)[T.Premium]</th>   <td>    0.0841</td> <td>    0.046</td> <td>    1.832</td> <td> 0.067</td> <td>   -0.006</td> <td>    0.174</td>\n</tr>\n<tr>\n  <th>C(color)[T.E]:C(cut)[T.Very Good]</th> <td>   -0.0931</td> <td>    0.041</td> <td>   -2.294</td> <td> 0.022</td> <td>   -0.173</td> <td>   -0.014</td>\n</tr>\n<tr>\n  <th>C(color)[T.F]:C(cut)[T.Very Good]</th> <td>   -0.1013</td> <td>    0.041</td> <td>   -2.459</td> <td> 0.014</td> <td>   -0.182</td> <td>   -0.021</td>\n</tr>\n<tr>\n  <th>C(color)[T.H]:C(cut)[T.Very Good]</th> <td>   -0.0247</td> <td>    0.043</td> <td>   -0.576</td> <td> 0.564</td> <td>   -0.109</td> <td>    0.059</td>\n</tr>\n<tr>\n  <th>C(color)[T.I]:C(cut)[T.Very Good]</th> <td>    0.0359</td> <td>    0.048</td> <td>    0.753</td> <td> 0.451</td> <td>   -0.057</td> <td>    0.129</td>\n</tr>\n</table>\n<table class=\"simpletable\">\n<tr>\n  <th>Omnibus:</th>       <td>4862.888</td> <th>  Durbin-Watson:     </th> <td>   0.101</td> \n</tr>\n<tr>\n  <th>Prob(Omnibus):</th>  <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>1246.556</td> \n</tr>\n<tr>\n  <th>Skew:</th>           <td> 0.108</td>  <th>  Prob(JB):          </th> <td>2.06e-271</td>\n</tr>\n<tr>\n  <th>Kurtosis:</th>       <td> 2.100</td>  <th>  Cond. No.          </th> <td>    20.8</td> \n</tr>\n</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.",
            "text/latex": "\\begin{center}\n\\begin{tabular}{lclc}\n\\toprule\n\\textbf{Dep. Variable:}                    &    log\\_price    & \\textbf{  R-squared:         } &     0.046   \\\\\n\\textbf{Model:}                            &       OLS        & \\textbf{  Adj. R-squared:    } &     0.045   \\\\\n\\textbf{Method:}                           &  Least Squares   & \\textbf{  F-statistic:       } &     119.5   \\\\\n\\textbf{Date:}                             & Fri, 13 Feb 2026 & \\textbf{  Prob (F-statistic):} &     0.00    \\\\\n\\textbf{Time:}                             &     09:17:21     & \\textbf{  Log-Likelihood:    } &   -49159.   \\\\\n\\textbf{No. Observations:}                 &       34935      & \\textbf{  AIC:               } & 9.835e+04   \\\\\n\\textbf{Df Residuals:}                     &       34920      & \\textbf{  BIC:               } & 9.847e+04   \\\\\n\\textbf{Df Model:}                         &          14      & \\textbf{                     } &             \\\\\n\\textbf{Covariance Type:}                  &    nonrobust     & \\textbf{                     } &             \\\\\n\\bottomrule\n\\end{tabular}\n\\begin{tabular}{lcccccc}\n                                           & \\textbf{coef} & \\textbf{std err} & \\textbf{t} & \\textbf{P$> |$t$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n\\midrule\n\\textbf{Intercept}                         &       7.4567  &        0.019     &   401.583  &         0.000        &        7.420    &        7.493     \\\\\n\\textbf{C(color)[T.E]}                     &      -0.0056  &        0.024     &    -0.231  &         0.817        &       -0.053    &        0.042     \\\\\n\\textbf{C(color)[T.F]}                     &       0.1755  &        0.024     &     7.166  &         0.000        &        0.128    &        0.224     \\\\\n\\textbf{C(color)[T.H]}                     &       0.2756  &        0.026     &    10.739  &         0.000        &        0.225    &        0.326     \\\\\n\\textbf{C(color)[T.I]}                     &       0.3787  &        0.028     &    13.294  &         0.000        &        0.323    &        0.435     \\\\\n\\textbf{C(cut)[T.Premium]}                 &       0.2828  &        0.031     &     9.153  &         0.000        &        0.222    &        0.343     \\\\\n\\textbf{C(cut)[T.Very Good]}               &       0.2295  &        0.031     &     7.290  &         0.000        &        0.168    &        0.291     \\\\\n\\textbf{C(color)[T.E]:C(cut)[T.Premium]}   &      -0.0322  &        0.040     &    -0.800  &         0.424        &       -0.111    &        0.047     \\\\\n\\textbf{C(color)[T.F]:C(cut)[T.Premium]}   &       0.0313  &        0.040     &     0.775  &         0.438        &       -0.048    &        0.110     \\\\\n\\textbf{C(color)[T.H]:C(cut)[T.Premium]}   &       0.0947  &        0.041     &     2.308  &         0.021        &        0.014    &        0.175     \\\\\n\\textbf{C(color)[T.I]:C(cut)[T.Premium]}   &       0.0841  &        0.046     &     1.832  &         0.067        &       -0.006    &        0.174     \\\\\n\\textbf{C(color)[T.E]:C(cut)[T.Very Good]} &      -0.0931  &        0.041     &    -2.294  &         0.022        &       -0.173    &       -0.014     \\\\\n\\textbf{C(color)[T.F]:C(cut)[T.Very Good]} &      -0.1013  &        0.041     &    -2.459  &         0.014        &       -0.182    &       -0.021     \\\\\n\\textbf{C(color)[T.H]:C(cut)[T.Very Good]} &      -0.0247  &        0.043     &    -0.576  &         0.564        &       -0.109    &        0.059     \\\\\n\\textbf{C(color)[T.I]:C(cut)[T.Very Good]} &       0.0359  &        0.048     &     0.753  &         0.451        &       -0.057    &        0.129     \\\\\n\\bottomrule\n\\end{tabular}\n\\begin{tabular}{lclc}\n\\textbf{Omnibus:}       & 4862.888 & \\textbf{  Durbin-Watson:     } &     0.101  \\\\\n\\textbf{Prob(Omnibus):} &   0.000  & \\textbf{  Jarque-Bera (JB):  } &  1246.556  \\\\\n\\textbf{Skew:}          &   0.108  & \\textbf{  Prob(JB):          } & 2.06e-271  \\\\\n\\textbf{Kurtosis:}      &   2.100  & \\textbf{  Cond. No.          } &      20.8  \\\\\n\\bottomrule\n\\end{tabular}\n%\\caption{OLS Regression Results}\n\\end{center}\n\nNotes: \\newline\n [1] Standard Errors assume that the covariance matrix of the errors is correctly specified.",
            "text/plain": "<class 'statsmodels.iolib.summary.Summary'>\n\"\"\"\n                            OLS Regression Results                            \n==============================================================================\nDep. Variable:              log_price   R-squared:                       0.046\nModel:                            OLS   Adj. R-squared:                  0.045\nMethod:                 Least Squares   F-statistic:                     119.5\nDate:                Fri, 13 Feb 2026   Prob (F-statistic):               0.00\nTime:                        09:17:21   Log-Likelihood:                -49159.\nNo. Observations:               34935   AIC:                         9.835e+04\nDf Residuals:                   34920   BIC:                         9.847e+04\nDf Model:                          14                                         \nCovariance Type:            nonrobust                                         \n=====================================================================================================\n                                        coef    std err          t      P>|t|      [0.025      0.975]\n-----------------------------------------------------------------------------------------------------\nIntercept                             7.4567      0.019    401.583      0.000       7.420       7.493\nC(color)[T.E]                        -0.0056      0.024     -0.231      0.817      -0.053       0.042\nC(color)[T.F]                         0.1755      0.024      7.166      0.000       0.128       0.224\nC(color)[T.H]                         0.2756      0.026     10.739      0.000       0.225       0.326\nC(color)[T.I]                         0.3787      0.028     13.294      0.000       0.323       0.435\nC(cut)[T.Premium]                     0.2828      0.031      9.153      0.000       0.222       0.343\nC(cut)[T.Very Good]                   0.2295      0.031      7.290      0.000       0.168       0.291\nC(color)[T.E]:C(cut)[T.Premium]      -0.0322      0.040     -0.800      0.424      -0.111       0.047\nC(color)[T.F]:C(cut)[T.Premium]       0.0313      0.040      0.775      0.438      -0.048       0.110\nC(color)[T.H]:C(cut)[T.Premium]       0.0947      0.041      2.308      0.021       0.014       0.175\nC(color)[T.I]:C(cut)[T.Premium]       0.0841      0.046      1.832      0.067      -0.006       0.174\nC(color)[T.E]:C(cut)[T.Very Good]    -0.0931      0.041     -2.294      0.022      -0.173      -0.014\nC(color)[T.F]:C(cut)[T.Very Good]    -0.1013      0.041     -2.459      0.014      -0.182      -0.021\nC(color)[T.H]:C(cut)[T.Very Good]    -0.0247      0.043     -0.576      0.564      -0.109       0.059\nC(color)[T.I]:C(cut)[T.Very Good]     0.0359      0.048      0.753      0.451      -0.057       0.129\n==============================================================================\nOmnibus:                     4862.888   Durbin-Watson:                   0.101\nProb(Omnibus):                  0.000   Jarque-Bera (JB):             1246.556\nSkew:                           0.108   Prob(JB):                    2.06e-271\nKurtosis:                       2.100   Cond. No.                         20.8\n==============================================================================\n\nNotes:\n[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n\"\"\""
          },
          "metadata": {}
        }
      ],
      "execution_count": 44
    },
    {
      "id": "4a82102b-f291-4049-89e3-3c02d1cfaac6",
      "cell_type": "markdown",
      "source": "Based on the model summary table, many of the color grades' and cuts' associated beta coefficients have a p-value of less than 0.05 (check the P>|t| column). Additionally, some of the interactions also seem statistically significant. We'll use a two-way ANOVA to examine further the relationships between price and the two categories {color grade and cut}.\n\nFirst, we have to state our three pairs of null and alternative hypotheses:\n**Null Hypothesis (Color)**\n$H_0$ : $price_D$ = $price_E$ = $price_F$ = $price_H$ = $price_I$\n\nThere is no difference in the price of diamonds based on color.\n\n**Alternative Hypothesis (Color)**\n$H_1$ : Not $price_D$ = $price_E$ = $price_F$ = $price_H$ = $price_I$\nThere is a difference in the price of diamonds based on color.\n\n**Null Hypothesis (Cut)**\n$H_0$ :  $price_Ideal$ = $price_Premium$ = $price_VeryGood$ \n\nThere is no difference in the price of diamonds based on cut.\n\n**Alternative Hypothesis (Cut)**\n$H_1$ : Not $price_Ideal$ = $price_Premium$ = $price_VeryGood$ \n\nThere is a difference in the price of diamonds based on cut.\n\n**Null Hypothesis (Interaction)**\n$H_0$ : The effect of color on diamond price is independent of the cut and vice versa\n\n**Alternative Hypothesis (Interaction)**\n$H_1$ : There is an interatcion effect between color and cut on diamond price.\n\nThe syntax for a two-way ANOVA is the same as for a one-way ANOVA. We will continue to use the anova_lm() function from statsmodels.stats.",
      "metadata": {}
    },
    {
      "id": "0f09626f-aa14-49fb-bdd3-c7b076d4f4e0",
      "cell_type": "code",
      "source": "# Run two-way ANOVA\nsm.stats.anova_lm(model2, typ =2)",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "execution_count": 46,
          "output_type": "execute_result",
          "data": {
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>sum_sq</th>\n      <th>df</th>\n      <th>F</th>\n      <th>PR(&gt;F)</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>C(color)</th>\n      <td>926.361461</td>\n      <td>4.0</td>\n      <td>237.014783</td>\n      <td>3.481145e-201</td>\n    </tr>\n    <tr>\n      <th>C(cut)</th>\n      <td>630.641441</td>\n      <td>2.0</td>\n      <td>322.706309</td>\n      <td>1.348511e-139</td>\n    </tr>\n    <tr>\n      <th>C(color):C(cut)</th>\n      <td>27.478611</td>\n      <td>8.0</td>\n      <td>3.515279</td>\n      <td>4.531734e-04</td>\n    </tr>\n    <tr>\n      <th>Residual</th>\n      <td>34120.806577</td>\n      <td>34920.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
            "text/plain": "                       sum_sq       df           F         PR(>F)\nC(color)           926.361461      4.0  237.014783  3.481145e-201\nC(cut)             630.641441      2.0  322.706309  1.348511e-139\nC(color):C(cut)     27.478611      8.0    3.515279   4.531734e-04\nResidual         34120.806577  34920.0         NaN            NaN"
          },
          "metadata": {}
        }
      ],
      "execution_count": 47
    },
    {
      "id": "352028fa-d46e-4d09-b7b5-79ba6aaa85ef",
      "cell_type": "code",
      "source": "sm.stats.anova_lm(model2, typ =1)",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "execution_count": 47,
          "output_type": "execute_result",
          "data": {
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>df</th>\n      <th>sum_sq</th>\n      <th>mean_sq</th>\n      <th>F</th>\n      <th>PR(&gt;F)</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>C(color)</th>\n      <td>4.0</td>\n      <td>977.195814</td>\n      <td>244.298954</td>\n      <td>250.021037</td>\n      <td>3.747388e-212</td>\n    </tr>\n    <tr>\n      <th>C(cut)</th>\n      <td>2.0</td>\n      <td>630.641441</td>\n      <td>315.320721</td>\n      <td>322.706309</td>\n      <td>1.348511e-139</td>\n    </tr>\n    <tr>\n      <th>C(color):C(cut)</th>\n      <td>8.0</td>\n      <td>27.478611</td>\n      <td>3.434826</td>\n      <td>3.515279</td>\n      <td>4.531734e-04</td>\n    </tr>\n    <tr>\n      <th>Residual</th>\n      <td>34920.0</td>\n      <td>34120.806577</td>\n      <td>0.977114</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
            "text/plain": "                      df        sum_sq     mean_sq           F         PR(>F)\nC(color)             4.0    977.195814  244.298954  250.021037  3.747388e-212\nC(cut)               2.0    630.641441  315.320721  322.706309  1.348511e-139\nC(color):C(cut)      8.0     27.478611    3.434826    3.515279   4.531734e-04\nResidual         34920.0  34120.806577    0.977114         NaN            NaN"
          },
          "metadata": {}
        }
      ],
      "execution_count": 48
    },
    {
      "id": "c18d79c4-4d8a-4ba9-b85e-3be97ed5f77e",
      "cell_type": "code",
      "source": "sm.stats.anova_lm(model2, typ = 3)",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "execution_count": 48,
          "output_type": "execute_result",
          "data": {
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>sum_sq</th>\n      <th>df</th>\n      <th>F</th>\n      <th>PR(&gt;F)</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>Intercept</th>\n      <td>157578.043681</td>\n      <td>1.0</td>\n      <td>161268.910012</td>\n      <td>0.000000e+00</td>\n    </tr>\n    <tr>\n      <th>C(color)</th>\n      <td>319.145817</td>\n      <td>4.0</td>\n      <td>81.655250</td>\n      <td>4.134649e-69</td>\n    </tr>\n    <tr>\n      <th>C(cut)</th>\n      <td>100.144107</td>\n      <td>2.0</td>\n      <td>51.244864</td>\n      <td>5.987341e-23</td>\n    </tr>\n    <tr>\n      <th>C(color):C(cut)</th>\n      <td>27.478611</td>\n      <td>8.0</td>\n      <td>3.515279</td>\n      <td>4.531734e-04</td>\n    </tr>\n    <tr>\n      <th>Residual</th>\n      <td>34120.806577</td>\n      <td>34920.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
            "text/plain": "                        sum_sq       df              F        PR(>F)\nIntercept        157578.043681      1.0  161268.910012  0.000000e+00\nC(color)            319.145817      4.0      81.655250  4.134649e-69\nC(cut)              100.144107      2.0      51.244864  5.987341e-23\nC(color):C(cut)      27.478611      8.0       3.515279  4.531734e-04\nResidual          34120.806577  34920.0            NaN           NaN"
          },
          "metadata": {}
        }
      ],
      "execution_count": 49
    },
    {
      "id": "a1e61945-9bb0-484e-83f9-c7b1e2a4fe3e",
      "cell_type": "markdown",
      "source": "Since all of the p-values (column PR(>F)) are very small, we can reject all three null hypotheses.",
      "metadata": {}
    },
    {
      "id": "95139933-62c8-49d3-b86f-da55644c2edf",
      "cell_type": "markdown",
      "source": "# ANOVA post hoc test (Part II)",
      "metadata": {}
    },
    {
      "id": "7597981b-a2bb-4cb1-92e4-bf03e25367e6",
      "cell_type": "markdown",
      "source": "The focus is on post hoc tests after one-way ANOVA using the statsmodels package in Python.\n\nRecall the following definitions:\n\nOne-way ANOVA: Compares the means of one continuous dependent variable based on three or more groups of one categorical variable.\nPost hoc test: Performs a pairwise comparison between all available groups while controlling for the error rate.\nNote: Recall that if we run multiple hypothesis tests all with a 95% confidence level, there is an increasing chance of a false positive, or falsely rejecting the null hypothesis. The post hoc test will control for this, and allows us to run many hypothesis tests while remaining confident with the accuracy of the results. Otherwise, be very careful when running multiple hypothesis tests.",
      "metadata": {}
    },
    {
      "id": "795b4c2a-30ec-4d02-90f1-ff194b6cffcd",
      "cell_type": "markdown",
      "source": "We'll start by importing the statsmodels package and the ols function so we can construct a simple linear regression model. Next, we load in the dataset from the one-way ANOVA.",
      "metadata": {}
    },
    {
      "id": "7e56ccb6-80b3-45b1-a5a0-5e2b3f95b425",
      "cell_type": "code",
      "source": "# Import statsmodels package and ols function\nimport statsmodels.api as sm\nfrom statsmodels.formula.api import ols",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": 50
    },
    {
      "id": "fb3e49ce-3002-443d-ac7e-68bd9b62eb4e",
      "cell_type": "markdown",
      "source": "One-way ANOVA\nHere we follow the same steps as above:\n\n1. Build a simple linear regression model\n2. Check the results\n3. Run one-way ANOVA",
      "metadata": {}
    },
    {
      "id": "98d52490-8c23-4096-90f5-0cd1be8efc06",
      "cell_type": "code",
      "source": "# Construct simple linear regression model, and fit the model\nmodel = ols(formula = 'log_price  ~ C(color)', data = colorless_diamonds).fit()",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": 53
    },
    {
      "id": "86d39ee7-932f-4eee-bc95-93265c098286",
      "cell_type": "code",
      "source": "# Get summary statistics\nmodel.summary()",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "execution_count": 53,
          "output_type": "execute_result",
          "data": {
            "text/html": "<table class=\"simpletable\">\n<caption>OLS Regression Results</caption>\n<tr>\n  <th>Dep. Variable:</th>        <td>log_price</td>    <th>  R-squared:         </th> <td>   0.026</td> \n</tr>\n<tr>\n  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.026</td> \n</tr>\n<tr>\n  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   265.0</td> \n</tr>\n<tr>\n  <th>Date:</th>             <td>Fri, 13 Feb 2026</td> <th>  Prob (F-statistic):</th> <td>3.61e-225</td>\n</tr>\n<tr>\n  <th>Time:</th>                 <td>10:27:14</td>     <th>  Log-Likelihood:    </th> <td> -56182.</td> \n</tr>\n<tr>\n  <th>No. Observations:</th>      <td> 39840</td>      <th>  AIC:               </th> <td>1.124e+05</td>\n</tr>\n<tr>\n  <th>Df Residuals:</th>          <td> 39835</td>      <th>  BIC:               </th> <td>1.124e+05</td>\n</tr>\n<tr>\n  <th>Df Model:</th>              <td>     4</td>      <th>                     </th>     <td> </td>    \n</tr>\n<tr>\n  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n</tr>\n</table>\n<table class=\"simpletable\">\n<tr>\n        <td></td>           <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n</tr>\n<tr>\n  <th>Intercept</th>     <td>    7.6169</td> <td>    0.012</td> <td>  632.421</td> <td> 0.000</td> <td>    7.593</td> <td>    7.641</td>\n</tr>\n<tr>\n  <th>C(color)[T.E]</th> <td>   -0.0375</td> <td>    0.016</td> <td>   -2.394</td> <td> 0.017</td> <td>   -0.068</td> <td>   -0.007</td>\n</tr>\n<tr>\n  <th>C(color)[T.F]</th> <td>    0.1455</td> <td>    0.016</td> <td>    9.240</td> <td> 0.000</td> <td>    0.115</td> <td>    0.176</td>\n</tr>\n<tr>\n  <th>C(color)[T.H]</th> <td>    0.3015</td> <td>    0.016</td> <td>   18.579</td> <td> 0.000</td> <td>    0.270</td> <td>    0.333</td>\n</tr>\n<tr>\n  <th>C(color)[T.I]</th> <td>    0.4061</td> <td>    0.018</td> <td>   22.479</td> <td> 0.000</td> <td>    0.371</td> <td>    0.441</td>\n</tr>\n</table>\n<table class=\"simpletable\">\n<tr>\n  <th>Omnibus:</th>       <td>7112.992</td> <th>  Durbin-Watson:     </th> <td>   0.065</td>\n</tr>\n<tr>\n  <th>Prob(Omnibus):</th>  <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>1542.881</td>\n</tr>\n<tr>\n  <th>Skew:</th>           <td> 0.079</td>  <th>  Prob(JB):          </th> <td>    0.00</td>\n</tr>\n<tr>\n  <th>Kurtosis:</th>       <td> 2.049</td>  <th>  Cond. No.          </th> <td>    6.32</td>\n</tr>\n</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.",
            "text/latex": "\\begin{center}\n\\begin{tabular}{lclc}\n\\toprule\n\\textbf{Dep. Variable:}    &    log\\_price    & \\textbf{  R-squared:         } &     0.026   \\\\\n\\textbf{Model:}            &       OLS        & \\textbf{  Adj. R-squared:    } &     0.026   \\\\\n\\textbf{Method:}           &  Least Squares   & \\textbf{  F-statistic:       } &     265.0   \\\\\n\\textbf{Date:}             & Fri, 13 Feb 2026 & \\textbf{  Prob (F-statistic):} & 3.61e-225   \\\\\n\\textbf{Time:}             &     10:27:14     & \\textbf{  Log-Likelihood:    } &   -56182.   \\\\\n\\textbf{No. Observations:} &       39840      & \\textbf{  AIC:               } & 1.124e+05   \\\\\n\\textbf{Df Residuals:}     &       39835      & \\textbf{  BIC:               } & 1.124e+05   \\\\\n\\textbf{Df Model:}         &           4      & \\textbf{                     } &             \\\\\n\\textbf{Covariance Type:}  &    nonrobust     & \\textbf{                     } &             \\\\\n\\bottomrule\n\\end{tabular}\n\\begin{tabular}{lcccccc}\n                       & \\textbf{coef} & \\textbf{std err} & \\textbf{t} & \\textbf{P$> |$t$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n\\midrule\n\\textbf{Intercept}     &       7.6169  &        0.012     &   632.421  &         0.000        &        7.593    &        7.641     \\\\\n\\textbf{C(color)[T.E]} &      -0.0375  &        0.016     &    -2.394  &         0.017        &       -0.068    &       -0.007     \\\\\n\\textbf{C(color)[T.F]} &       0.1455  &        0.016     &     9.240  &         0.000        &        0.115    &        0.176     \\\\\n\\textbf{C(color)[T.H]} &       0.3015  &        0.016     &    18.579  &         0.000        &        0.270    &        0.333     \\\\\n\\textbf{C(color)[T.I]} &       0.4061  &        0.018     &    22.479  &         0.000        &        0.371    &        0.441     \\\\\n\\bottomrule\n\\end{tabular}\n\\begin{tabular}{lclc}\n\\textbf{Omnibus:}       & 7112.992 & \\textbf{  Durbin-Watson:     } &    0.065  \\\\\n\\textbf{Prob(Omnibus):} &   0.000  & \\textbf{  Jarque-Bera (JB):  } & 1542.881  \\\\\n\\textbf{Skew:}          &   0.079  & \\textbf{  Prob(JB):          } &     0.00  \\\\\n\\textbf{Kurtosis:}      &   2.049  & \\textbf{  Cond. No.          } &     6.32  \\\\\n\\bottomrule\n\\end{tabular}\n%\\caption{OLS Regression Results}\n\\end{center}\n\nNotes: \\newline\n [1] Standard Errors assume that the covariance matrix of the errors is correctly specified.",
            "text/plain": "<class 'statsmodels.iolib.summary.Summary'>\n\"\"\"\n                            OLS Regression Results                            \n==============================================================================\nDep. Variable:              log_price   R-squared:                       0.026\nModel:                            OLS   Adj. R-squared:                  0.026\nMethod:                 Least Squares   F-statistic:                     265.0\nDate:                Fri, 13 Feb 2026   Prob (F-statistic):          3.61e-225\nTime:                        10:27:14   Log-Likelihood:                -56182.\nNo. Observations:               39840   AIC:                         1.124e+05\nDf Residuals:                   39835   BIC:                         1.124e+05\nDf Model:                           4                                         \nCovariance Type:            nonrobust                                         \n=================================================================================\n                    coef    std err          t      P>|t|      [0.025      0.975]\n---------------------------------------------------------------------------------\nIntercept         7.6169      0.012    632.421      0.000       7.593       7.641\nC(color)[T.E]    -0.0375      0.016     -2.394      0.017      -0.068      -0.007\nC(color)[T.F]     0.1455      0.016      9.240      0.000       0.115       0.176\nC(color)[T.H]     0.3015      0.016     18.579      0.000       0.270       0.333\nC(color)[T.I]     0.4061      0.018     22.479      0.000       0.371       0.441\n==============================================================================\nOmnibus:                     7112.992   Durbin-Watson:                   0.065\nProb(Omnibus):                  0.000   Jarque-Bera (JB):             1542.881\nSkew:                           0.079   Prob(JB):                         0.00\nKurtosis:                       2.049   Cond. No.                         6.32\n==============================================================================\n\nNotes:\n[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n\"\"\""
          },
          "metadata": {}
        }
      ],
      "execution_count": 54
    },
    {
      "id": "73c07ff0-c3c1-496b-a72a-05c1fc099869",
      "cell_type": "markdown",
      "source": "Now that we have reconstructed the simple linear regression model, we can re-run the ANOVA.",
      "metadata": {}
    },
    {
      "id": "45ef9b75-9bd2-4366-9a4d-0adc71609c21",
      "cell_type": "code",
      "source": "# Run one-way ANOVA\nsm.stats.anova_lm(model, typ = 2)",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "execution_count": 54,
          "output_type": "execute_result",
          "data": {
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>sum_sq</th>\n      <th>df</th>\n      <th>F</th>\n      <th>PR(&gt;F)</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>C(color)</th>\n      <td>1041.690290</td>\n      <td>4.0</td>\n      <td>264.987395</td>\n      <td>3.609774e-225</td>\n    </tr>\n    <tr>\n      <th>Residual</th>\n      <td>39148.779822</td>\n      <td>39835.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
            "text/plain": "                sum_sq       df           F         PR(>F)\nC(color)   1041.690290      4.0  264.987395  3.609774e-225\nResidual  39148.779822  39835.0         NaN            NaN"
          },
          "metadata": {}
        }
      ],
      "execution_count": 55
    },
    {
      "id": "6f76980f-1167-4c38-aab8-29320ca5d924",
      "cell_type": "markdown",
      "source": "Since the p-value is very small and we can reject the null hypothesis that the mean price is the same for all diamond color grades, we can continue on to run a post hoc test. The post hoc test is useful because the one-way ANOVA does not tell us which colors are associated with different prices. The post hoc test will give us more information.",
      "metadata": {}
    },
    {
      "id": "5d65e670-3f10-4ba1-a451-f92590f6cf14",
      "cell_type": "markdown",
      "source": "**Post hoc test**\nThere are many post hoc tests that can be run. One of the most common ANOVA post hoc tests is the **Tukey's HSD (honestly significantly different)** test. We can import the pairwise_tukeyhsd() function from the statsmodels package to run the test.",
      "metadata": {}
    },
    {
      "id": "5f87f35b-809d-4c61-b997-f9e4bb0613a3",
      "cell_type": "code",
      "source": "# Import Tukey's HSD function\nfrom statsmodels.stats.multicomp import pairwise_tukeyhsd",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": 56
    },
    {
      "id": "4b0bf919-cf21-4158-b38d-cacf89f7fe27",
      "cell_type": "raw",
      "source": "Then we can run the test. The endog variable specifies which variable is being compared across groups, which is log_price in this case. Then the groups variables indicates which variable holds the groups we're comparing, which is color. alpha tells the function the significance or confidence level, which we'll set to 0.05. We'll aim for the typical 95% confidence level.",
      "metadata": {}
    },
    {
      "id": "df21f4e6-aabb-4a55-b1af-e2ecfb044b95",
      "cell_type": "code",
      "source": "# Run Tukey's HSD post hoc test for one-way ANOVA\ntukey_oneway = pairwise_tukeyhsd(endog = colorless_diamonds['log_price'],\n                                 groups = colorless_diamonds['color'],\n                                 alpha = 0.05)",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": 58
    },
    {
      "id": "588f91e3-9259-4619-810f-1d218df41bc2",
      "cell_type": "code",
      "source": "# Get results (pairwise comparisons)\ntukey_oneway.summary()",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "execution_count": 58,
          "output_type": "execute_result",
          "data": {
            "text/html": "<table class=\"simpletable\">\n<caption>Multiple Comparison of Means - Tukey HSD, FWER=0.05</caption>\n<tr>\n  <th>group1</th> <th>group2</th> <th>meandiff</th>  <th>p-adj</th>  <th>lower</th>   <th>upper</th> <th>reject</th>\n</tr>\n<tr>\n     <td>D</td>      <td>E</td>    <td>-0.0375</td> <td>0.1169</td> <td>-0.0802</td> <td>0.0052</td>  <td>False</td>\n</tr>\n<tr>\n     <td>D</td>      <td>F</td>    <td>0.1455</td>    <td>0.0</td>  <td>0.1026</td>  <td>0.1885</td>  <td>True</td> \n</tr>\n<tr>\n     <td>D</td>      <td>H</td>    <td>0.3015</td>    <td>0.0</td>  <td>0.2573</td>  <td>0.3458</td>  <td>True</td> \n</tr>\n<tr>\n     <td>D</td>      <td>I</td>    <td>0.4061</td>    <td>0.0</td>  <td>0.3568</td>  <td>0.4553</td>  <td>True</td> \n</tr>\n<tr>\n     <td>E</td>      <td>F</td>     <td>0.183</td>    <td>0.0</td>  <td>0.1441</td>  <td>0.2219</td>  <td>True</td> \n</tr>\n<tr>\n     <td>E</td>      <td>H</td>     <td>0.339</td>    <td>0.0</td>  <td>0.2987</td>  <td>0.3794</td>  <td>True</td> \n</tr>\n<tr>\n     <td>E</td>      <td>I</td>    <td>0.4436</td>    <td>0.0</td>  <td>0.3978</td>  <td>0.4893</td>  <td>True</td> \n</tr>\n<tr>\n     <td>F</td>      <td>H</td>     <td>0.156</td>    <td>0.0</td>  <td>0.1154</td>  <td>0.1966</td>  <td>True</td> \n</tr>\n<tr>\n     <td>F</td>      <td>I</td>    <td>0.2605</td>    <td>0.0</td>  <td>0.2145</td>  <td>0.3065</td>  <td>True</td> \n</tr>\n<tr>\n     <td>H</td>      <td>I</td>    <td>0.1045</td>    <td>0.0</td>  <td>0.0573</td>  <td>0.1517</td>  <td>True</td> \n</tr>\n</table>",
            "text/latex": "\\begin{center}\n\\begin{tabular}{ccccccc}\n\\toprule\n\\textbf{group1} & \\textbf{group2} & \\textbf{meandiff} & \\textbf{p-adj} & \\textbf{lower} & \\textbf{upper} & \\textbf{reject}  \\\\\n\\midrule\n       D        &        E        &      -0.0375      &     0.1169     &    -0.0802     &     0.0052     &      False       \\\\\n       D        &        F        &       0.1455      &      0.0       &     0.1026     &     0.1885     &       True       \\\\\n       D        &        H        &       0.3015      &      0.0       &     0.2573     &     0.3458     &       True       \\\\\n       D        &        I        &       0.4061      &      0.0       &     0.3568     &     0.4553     &       True       \\\\\n       E        &        F        &       0.183       &      0.0       &     0.1441     &     0.2219     &       True       \\\\\n       E        &        H        &       0.339       &      0.0       &     0.2987     &     0.3794     &       True       \\\\\n       E        &        I        &       0.4436      &      0.0       &     0.3978     &     0.4893     &       True       \\\\\n       F        &        H        &       0.156       &      0.0       &     0.1154     &     0.1966     &       True       \\\\\n       F        &        I        &       0.2605      &      0.0       &     0.2145     &     0.3065     &       True       \\\\\n       H        &        I        &       0.1045      &      0.0       &     0.0573     &     0.1517     &       True       \\\\\n\\bottomrule\n\\end{tabular}\n%\\caption{Multiple Comparison of Means - Tukey HSD, FWER=0.05}\n\\end{center}",
            "text/plain": "<class 'statsmodels.iolib.table.SimpleTable'>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 59
    },
    {
      "id": "600db47b-7123-4e4d-9f5c-26e77666da7e",
      "cell_type": "markdown",
      "source": "Each row represents a pariwise comparison between the prices of two diamond color grades. The reject column tells us which null hypotheses we can reject. Based on the values in that column, we can reject each null hypothesis, except when comparing D and E color diamonds. We cannot reject the null hypothesis that the diamond price of D and E color diamonds are the same.",
      "metadata": {}
    },
    {
      "id": "14aeab2d-ff74-4519-9881-b7bcbd21df0d",
      "cell_type": "markdown",
      "source": "**Test 1: D vs. E**\n$H_0$ :  $price_D$ = $price_E$\nThe price of D and E color grade diamonds are the same.\n\n$H_1$ : Not $price_D$ = $price_E$\nThe price of D and E color grade diamonds are not the same.\n\n**Result:** We cannot reject the null hypothesis that the price of D and E color grade diamonds are the same.\n\n**Test 2: D vs. F**\n$H_0$ :  $price_D$ = $price_F$\nThe price of D and F color grade diamonds are the same.\n\n$H_1$ : Not $price_D$ = $price_F$\nThe price of D and F color grade diamonds are not the same.\n\n**Result:** We can reject the null hypothesis that the price of D and F color grade diamonds are the same.\n\n**Test 3: D vs. H**\n$H_0$ :  $price_D$ = $price_H$\nThe price of D and H color grade diamonds are the same.\n\n$H_1$ : Not $price_D$ = $price_H$\nThe price of D and H color grade diamonds are not the same.\n\n**Result:** We can reject the null hypothesis that the price of D and H color grade diamonds are the same.\n\n**Test 4: D vs. I**\n$H_0$ :  $price_D$ = $price_I$\nThe price of D and I color grade diamonds are the same.\n\n$H_1$ : Not $price_D$ = $price_I$\nThe price of D and I color grade diamonds are not the same.\n\n**Result:** We can reject the null hypothesis that the price of D and I color grade diamonds are the same.\n\n**Test 5: E vs. F**\n$H_0$ :  $price_E$ = $price_F$\nThe price of E and F color grade diamonds are the same.\n\n$H_1$ : Not $price_E$ = $price_F$\nThe price of E and F color grade diamonds are not the same.\n\n**Result:** We can reject the null hypothesis that the price of E and F color grade diamonds are the same.\n\n**Test 6: E vs. H**\n$H_0$ :  $price_E$ = $price_H$\nThe price of E and H color grade diamonds are the same.\n\n$H_1$ : Not $price_E$ = $price_H$\nThe price of E and H color grade diamonds are not the same.\n\n**Result:** We can reject the null hypothesis that the price of E and H color grade diamonds are the same.\n\n**Test 7: E vs. I**\n$H_0$ :  $price_E$ = $price_I$\nThe price of E and I color grade diamonds are the same.\n\n$H_1$ : Not $price_E$ = $price_I$\nThe price of E and I color grade diamonds are not the same.\n\n**Result:** We can reject the null hypothesis that the price of E and I color grade diamonds are the same.\n\n**Test 8: F vs. H**\n$H_0$ :  $price_F$ = $price_H$\nThe price of F and H color grade diamonds are the same.\n\n$H_1$ : Not $price_F$ = $price_H$\nThe price of F and H color grade diamonds are not the same.\n\n**Result:** We can reject the null hypothesis that the price of F and H color grade diamonds are the same.\n\n**Test 9: F vs. I**\n$H_0$ :  $price_F$ = $price_I$\nThe price of F and I color grade diamonds are the same.\n\n$H_1$ : Not $price_F$ = $price_I$\nThe price of F and I color grade diamonds are not the same.\n\n**Result:** We can reject the null hypothesis that the price of F and I color grade diamonds are the same.\n\n**Test 10: H vs. I**\n$H_0$ :  $price_H$ = $price_I$\nThe price of H and I color grade diamonds are the same.\n\n$H_1$ : Not $price_H$ = $price_I$\nThe price of H and I color grade diamonds are not the same.\n\n**Result:** We can reject the null hypothesis that the price of H and I color grade diamonds are the same.",
      "metadata": {}
    }
  ]
}